# *p*与*CI*使用情况调研问卷情境及相关选项的具体说明


## 一、基本说明
问卷使用了随机化分组的形式进行。根据系统设置，调查者被随机地分配到以下两种情境中。两种情境的*p*值与*CI*存在不同，目的是为了测量在拒绝与不拒绝原假设的情境下（即一般意义上的阳性结果与阴性结果情境）科研工作者对这两个统计指标的理解。

在本问卷中，不对显著性检验（test of significance）和假设检验（hypothesis testing）做区别，视为等同的术语。但对部分统计学家而言（尤其是显著性检验的提出者Ronald Fisher本人），两者之间存在本质区别，主要在于显著性检验只有原假设（Null hypothesis，H0，也翻译为零假设或者虚无假设，本文统一使用原假设）而无须引入备择假设（Alternative hypothesis，H1，也有称为实验假设，本文统一使用备择假设），也须考虑第二类错误。目前通常使用的显著性检验模式为原假设显著性检验（Null Hypothesis Significance Testing，简称NHST）。这一模式在NHST模式下，建立原假设和备择假设，选择检验统计量并计算其值，根据p值是否小于显著性水平、或临界值是否落入拒绝域做出是否拒绝原假设的统计判断，最后再将这种统计判断转化为现实情境下的行为判断（如实验处理、政策干预是否确实有效），成为假设检验的标准流程。

NHST模式起源于20世纪的统计学大家Ronald Fisher，并经由Jerzy Neyma和Egon Pearson的改造，但Fisher与Newman-Pearson之间在对假设检验的形式与功能的认识上存在诸多分歧。尽管如此，他们都属于频率学派统计学（Frequentist Statistics）的阵营，都反对贝叶斯学派统计学（Bayesian Statistics）的概率解释与检验模式。如无特殊说明，本次调查中的“检验”，均指NHST模式检验。以下分情境进行解释说明。两种情境下的说明在基本原理上存在高度的重复，仅就具体的选项的说明上存在差别。因此，建议读者根据本文提供的顺序进行阅读。

## 二、情境一（*p* = 0.008，CI：[0.1, 0.4]）的说明

### 问题1：*p*值

` 假设你进行了某项实验处理，并预期该处理能改变被试在特定任务中的表现。随后对控制组与实验组（每组50人）的任务表现得分均值进行比较。你建立如下假设形式：`

` 原假设（H0）：实验组与控制组对应的总体均值没有差别。`

` 备择假设（H1）：实验组与控制组对应的总体均值存在差别。`

` 你使用了简单的独立样本双侧t检验发现如下结果：t = 2.7, df = 98, p = 0.008。`

` 根据以上信息，请评判对每个陈述的对错，并且表明您对自己判断的信心。“错误”表示该论断无法从上述前提合乎逻辑地推断得出。注意：所有论断均可能是对的或错的。 `

` （1）	你已证实原假设是错的 `

` （2）	你发现了原假设为真的概率 `

` （3）	你可知道，因拒绝原假设而做出错误决策的概率（即错误地拒绝原假设的概率） `

` （4）	你得到了非常可靠的实验结果，因为若重复多次进行该实验，你可在超过99%的实验中得到显著结果 ` `


#### 解释说明：

所有陈述皆错。对*p* = 0.008的正确解释是：

如果实验组与控制组对应的总体均值确实没有差别（即如果原假设确实是正确的），那么重复此次实验，则在1000次实验中，约有8次实验结果会出现实验组与控制组的观测结果会大于等于本次观测到的均值差。

显著性检验不能证明或者证伪原假设或者备择假设）。显著性检验提供了在原假设为真情况下，出现当前数据结果及更极端结果模式的概率，只能作为某种理论的佐证。但是原假设是否为真，则超出这一方法本身的所能证明的范畴，而只是执行这一检验所必须引入的前提假设。因此，陈述（1）和（2）是错误的，显著性检验既不能告知任何假设（不论原假设还是备择假设）的对错，也就无法告知其对错的概率。

如果做出了拒绝原假设，那么只可能犯第一类错误。陈述（3）实际上是*α*错误（type I error，或称假阳性、一类错误、弃真错误）的定义，即H0为真时将之拒绝的概率，但是*p*值 ≠ *α*！*p*值的定义是：假定H0为真时，出现当前结果及更极端结果的概率；而显著性水平*α*则是人为规定的数值，以对基于显著性检验的行为决策的错误率进行控制。*p*值是个条件概率，要求H0为真，但H0是否为真则不可知。

通常规定*p* < *α*则拒绝原假设，反之则不拒绝原假设。这只是一个外在于具体实验和数学论证本身的决策法则，*α*是独立于*p*值而提前存在的。打个比方说，*α*相当于是考试的及格线，这在考试之前就已经存在并应明确公示；而*p*值则相当于考试的具体得分，只有在进行考试后才可得知。若把*α*控制在0.05，其意思是：如果进行无数次实验，则当H0为真时错误地将之拒绝的比例应该只有0.05。也就是说，*α*错误率是假定进行无数次实验后得到的一个值。若不知晓原假设是否为真，则永远无法判断在当前的这一次实验中，拒绝H0犯错的概率是多少。实际上，显著性检验并不能告知这一概率。

陈述（4）也是错误的。1－*p*并不是显著结果会被重复的概率。前面已经说过，*p*值的定义是：假定H0为真时，出现当前结果及更极端结果的概率。所以1－*p*是假定H0为真时，未出现当前结果及更极端结果的概率。同时，*p*值也不同等于*α*，不能将1－*p*理解为1－*α*。

在通常的实验中，在一定的显著性水平下（如*α*=0.05），若拒绝原假设，则可认为实验组与控制组在对应指标上存在差异（即实验处理是有效的、实验效应是存在的）；不能拒绝原假设，可认为实验组与控制组之间在对应指标上不存在差异。这里的“可认为”是一种看法，而并不是陈述一种事实；基于实验结果和显著性检验的结果，研究者可有一定的信心做出判断，但判断出错也是可能的。但很多时候，研究者把“看法”当成了“事实”。这实际上是一种“简化机制”，即把过程的合法性，等同于事实的合法性。

### 问题2：CI

` 某教授执行了一个随机化实验，分析实验组与控制组的数据后报告道：`

` “实验组与控制组的均值差的95%（双侧）置信区间为[0.1, 0.4]。” `

` 请评判对每个陈述的对错，并且表明您对自己判断的信心。“错误”表示该论断无法从上述前提合乎逻辑地推断得出。每个陈述均有可能是对的或错的。 `

` （1）	真实均值差/总体均值差有95%的概率落在0.1和0.4之间 `

` （2）	如果重复该实验，则95%的时候，真实均值差/总体均值差会落在0.1和0.4之间 `

` （3）	若原假设为“实验组与控制组对应的总体均值相等”，则此实验已证实该假设是错误的 `

` （4）	若原假设为“实验组与控制组对应的总体均值相等”，则因拒绝该假设而犯错的概率为5% `

#### 解释说明

所有陈述皆错。正确的解释为：若重复使用该方法计算出无数个置信区间，则有95%的置信区间包含真实均值/总体均值。

置信区间（此处仅指双侧置信区间）是一个基于统计量的点估计值而构造的随机区间，随着每一次实验（抽样）数据的不同，点估计值会发生变化，从而使用这一区间的端点发生变化。就单次实验（抽样）而言，若总体参数未知，则永远不知道这一次产生的置信区间是否包含真实均值/总体均值。同时，按提出置信区间这一方法的频率学派统计学的观点，总体参数本身是一个静止的常数，它本身不具备任何随机性，因此无法加之概率论断。所谓的95%置信区间，意指若重复使用构造该区间的统计方法，则所有产生的置信区间中，将有95%的区间能够包含真实均值/总体均值。也就是说，概率诊断应针对过程、而不针对参数而使用。若严格遵守频率学派的观点，任何对总体参数使用概率论断的论述均是不可接受的。如此，很容易判定陈述（1）、（2）是错误的，它们都对静止的参数值做了随机化的概率论断。

陈述（3）和（4）应结合前述的显著性检验说明来理解。就陈述（3）而言，实际上，在是否拒绝原假设上，许多统计教材正是将置信区间与显著性检验的方法“等同看待”的，其决策模式为：若置信区间包含“原假设”中假定的参数值（例如0），则不拒绝原假设/零假设；反之则拒绝。其“逻辑”在于：若“原假设”为真，则统计量的值很可能在这一参数值不远处，由此构造的置信区间很可能包含住参数真值。反之，若置信区间未包含假定的参数真值，则有可能是因为关于参数真值的假定本身是不合理的。这仍是与显著性检验相同的概率上的反证法的运用。也正由于置信区间不仅能够提供与显著性检验一样的二元化论断（拒绝/不拒绝），还能提供关于参数的一个区间估计，同时还从区间宽度或某侧端点与假定的参数值之间的距离在一定程度上给出估计精度的信息，因此，置信区间才被认为是优于只能给出纯粹二元化判断的显著性检验的替代方式。但是，前面已经说明，显著性检验本身并不能告知关于原假设正误的信息或概率，故陈述（3）、（4）是错误的。

就一个具体的置信区间而言，它要么包含真实均值，要么未包含真实均值，这是一个0-1事件，不涉及更复杂的概率论断；只有在无数次的重复构造中，它才能出现包含比例的特征。就一次实验的结果来做统计推断，其风险很大。然而它确实又可在一定程度上给出作为实验结果的统计量的实现值与未知的总体参数值之间的关系，因此，早期统计学家及统计方法的实践者使用了某种“折中化”的语言：将频率化的论述转化信心度的描述，并将之应用于具体的、某一次的置信区间。虽不可知总体均值是否被这一次置信区间所包含，但其结果可以为研究者产生某种行为决策提供某种程度的信心，故有时也称：“我们有95%的信心认为，总体均值差处在[0.1, 0.4]之间”。这一种非常模糊化的表达方式。但实际上，这正是“置信区间”一词的来源：在一次具体的实验（抽样）中，它描述的是信心度量（主观概率），而不是频率度量（客观概率），而这正好违背的频率学派统计学的初衷！

从前述论述可以看出，置信区间的解释也是复杂的、一定程度上偏离人类直觉概念的，人们的理解也容易产生歧义。用置信区间来替代*p*值做统计报告的推崇者，可能并未注意到置信区间的内在模糊性和多重理解可能(Morey, Hoekstra, Rouder, Lee, & Wagenmakers, 2016)。实际上，科研工作者对置信区间的理解程度，往往并不高于p值。希望通过某种统计指标的“切换”而达到研究准确性的提升，可能是过于乐观的。


## 二、情境二（*p* = 0.21，CI：[-0.1, 0.4]）的说明

### 问题1：*p*值

` 假设你进行了某项实验处理，并预期该处理能改变被试在特定任务中的表现。随后对控制组与实验组（每组50人）的任务表现得分均值进行比较。你建立如下假设形式：`

` 原假设（H0）：实验组与控制组对应的总体均值没有差别。`

` 备择假设（H1）：实验组与控制组对应的总体均值存在差别。`

` 你使用了简单的独立样本双侧t检验发现如下结果：t = 1.26, df = 98, p = 0.21。 `
 
` 根据以上信息，请评判对每个陈述的对错，并且表明您对自己判断的信心。“错误”表示该论断无法从上述前提合乎逻辑地推断得出。注意：所有论断均可能是对的或错的。 `

` （1）	你已证实原假设是对的 `

` （2）	你发现了备择假设为真的概率 `

` （3）	你可以知道，因拒绝原假设而做出错误决策的概率（即错误地拒绝原假设的概率） `

` （4）	你得到了不可靠的实验结果，因为若重复多次进行该实验，你只有在约21%的实验中得到显著结果 `

#### 解释说明

所有陈述皆错。

在情境一中的解释说明已经澄清，显著性检验不能告知任何有关原假设、备择假设的对错概率。如果未能拒绝原假设，只可能犯第二类错误。陈述（3）就是*β*错误（type II error，第二类错误、纳伪错误）的定义为若原假设为假而未能拒绝的概率。但要计算这一概率，首先必须知道原假设是否为真，而这在真实的研究中是不可能获知的，否则就不必再去做假设检验。

与前面情境一中的说明类似，陈述（4）误将1－*p*当成实验结果会被重复的概率，也是错误的。

正确的陈述请参照情境一做出理解。
  
### 问题2：CI

` 某教授执行了一个随机化实验，分析实验组与控制组的数据后报告道： `

` “实验组与控制组的均值差的95%（双侧）置信区间为[-0.1, 0.4]。”（请注意0.1前面的负号） `

` 请评判对每个陈述的对错，并且表明您对自己判断的信心。“错误”表示该论断无法从上述前提合乎逻辑地推断得出。每个陈述均有可能是对的或错的。 `

` （1）	真实均值差/总体均值差有95%的概率落在-0.1和0.4之间 `

` （2）	如果重复该实验，则95%的时候，真实均值差/总体均值差会落在-0.1和0.4之间 `

` （3）	若原假设/零假设为“实验组与控制组对应的总体均值相等”，则此实验已证实该假设是正确的 `

` （4）	若原假设为“实验组与控制组对应的总体均值相等”，则因未能拒绝该假设而犯错的概率为5% `

#### 解释说明

所有陈述皆错。

在情境一中的解释说明已经澄清，置信区间的随机性源自于产生这一区间的方法过程，而不是总体参数；区间是随机的，而参数永远静止、不能对之进行概率化论述。故陈述（1）、（2）错误。

陈述（3）同样对置信区间的结果进行过分绝对化的解读，陈述（4）则将*α*错误当成*β*错误的大小。

正确的陈述请参照情境一做出理解。

***

**发起人**

姓名 | 单位  | 职称  | 邮箱
-----|---------|-------|------
[吕小康](http://zfxy.nankai.edu.cn/xk) | [南开大学周恩来政府管理学院](http://zfxy.nankai.edu.cn/) | 副教授 | luxk@nankai.edu.cn
[胡传鹏](http://www.huchuanpeng.com/) | [清华大学社会科学学院](http://www.sss.tsinghua.edu.cn/)；[Neuroimaging Center](http://www.ftn.nic.uni-mainz.de/en/), [Mainz University](http://www.uni-mainz.de/eng/) | 博士；博士后 |  hucp12@mails.tsinghua.edu.cn
[赵晓繁](https://github.com/xiaofanzhao) | [南开大学周恩来政府管理学院](http://zfxy.nankai.edu.cn/)  | 硕士生 | zxfpsy@mail.nankai.edu.cn

如有任何疑问或拟商量合作调查事宜，请发信至上述任一邮箱，谢谢！


***
　　本次调查的设计与解释参照了多篇相关文献。为方便阅读，恕不一一列出。以下仅列出一些国内外的代表性文献，仅读者参考。
 
Altman, N., & Krzywinski, M. (2017). Points of significance: P values and the search for significance. *Nature Methods, 14*(1), 3–4. doi:10.1038/nmeth.4120.

Berger, J. O. (2003). Could Fisher, Jeffreys and Neyman Have Agreed on Testing? *Statistical Science, 18*(1), 28–32. 

Cohen, J. (1994). The earth is round (p < .05). *American Psychologist, 49*(12), 997–1003. doi:10.1037/0003-066X.49.12.997.

Fidler, F., Geoff, C., Mark, B., & Neil, T. (2004). Statistical reform in medicine, psychology and ecology. *The Journal of Socio-Economics, 33*(5), 615–630. doi: 10.1016/j.socec.2004.09.035.

Gigerenzer, G. (2004). Mindless statistics. *The Journal of Socio-Economics, 33*(5), 587–606. doi:10.1016/j.socec.2004.09.033.

Goodman, S. N. (2016). Aligning statistical and scientific reasoning. *Science, 352*(6290), 1180–1181. doi:10.1126/science.aaf5406.

Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. *European Journal of Epidemiology, 31*(4), 337–350. doi:10.1007/s10654-016-0149-3.

Haller, H., & Krauss, S. (2002). Misinterpretations of significance: a problem students share with their teachers. *Methods of Psychological Research Online, 7*(1), 1–20. 

Halsey, L. G., Curran-Everett, D., Vowler, S. L., & Drummond, G. B. (2015). The fickle P value generates irreproducible results. *Nature Methods, 12*(3), 179–185. doi:10.1038/nmeth.3288.

Hoekstra, R., Morey, R. D., Rouder, J., & Wagenmakers, E. J. (2014). Robust misinterpretation of confidence intervals. *Psychonomic Bulletin & Review, 21*(5), 1157–1164. doi:10.3758/s13423-013-0572-3.

Morey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., & Wagenmakers, E.-J. (2016). The fallacy of placing confidence in confidence intervals. *Psychonomic Bulletin & Review, 23*(1), 103–123. doi:10.3758/s13423-015-0947-8.

Nuzzo, R. (2014). Scientific method: Statistical errors. *Nature, 506*(7487), 150–152. doi:10.1038/506150a.

Wasserstein, R. L., & Lazar, N. A. (2016). The ASA's statement on p-values: context, process, and purpose. *The American Statistician, 70*(2), 129–133. doi:10.1080/00031305.2016.1154108.

Ziliak, S. T., & McCloskey, D. N. (2008). *The cult of statistical significance*. Ann Arbor: University of Michigan Press.

胡传鹏, 王非, 过继成思, 宋梦迪, 隋洁, 彭凯平. (2016). 心理学研究的可重复性问题: 从危机到契机. *心理科学进展, 24*(9), 1504–1518 doi:10.3724/SP.J.1042.2016.01504.

吕小康. (2014). 从工具到范式: 假设检验争议的知识社会学反思. *社会, 34* (6), 216–236.


















